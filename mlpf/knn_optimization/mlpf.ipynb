{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember to do \"pip install .\" on https://github.com/mandylee900125/pytorch_cmspepr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------PACKAGES IMPORT----------------------\n",
    "import numpy as np\n",
    "import mplhep, time, os\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import EdgeConv, MessagePassing, EdgePooling, GATConv, GCNConv, JumpingKnowledge, GraphUNet, DynamicEdgeConv, DenseGCNConv\n",
    "from torch_geometric.nn import TopKPooling, SAGPooling, SGConv\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.data import Data, DataLoader, DataListLoader, Batch\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------PFNet8(Before)---------------------\n",
    "#Run this in order to run the comparison\n",
    "\n",
    "from gravnet2 import GravNetConv\n",
    "GravNetConv2 = GravNetConv\n",
    "class PFNet8(nn.Module):\n",
    "    def __init__(self,\n",
    "        input_dim=12, hidden_dim=256, hidden_dim_nn1=64, input_encoding=12, encoding_dim=64,\n",
    "        output_dim_id=6,\n",
    "        output_dim_p4=6,\n",
    "        space_dim=4, propagate_dimensions=22, nearest=16,\n",
    "        target=\"gen\"):\n",
    "\n",
    "        super(PFNet8, self).__init__()\n",
    "\n",
    "        self.elu = nn.ELU\n",
    "        self.act_f = torch.nn.functional.leaky_relu\n",
    "\n",
    "        # (1) DNN: encoding/decoding of all tracks and clusters\n",
    "        self.nn1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim_nn1),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim_nn1, hidden_dim_nn1),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim_nn1, input_encoding),\n",
    "        )\n",
    "\n",
    "        # (2) CNN: Gravnet layer\n",
    "        self.conv1 = GravNetConv2(input_encoding, encoding_dim, space_dim, propagate_dimensions, nearest)\n",
    "\n",
    "        # (3) DNN layer: classifying PID\n",
    "        self.nn2 = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, output_dim_id),\n",
    "        )\n",
    "\n",
    "        # (4) DNN layer: regressing p4\n",
    "        self.nn3 = nn.Sequential(\n",
    "            nn.Linear(encoding_dim + output_dim_id + input_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, output_dim_p4),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x0 = data.x\n",
    "\n",
    "        # Encoder/Decoder step\n",
    "        x = self.nn1(x0)\n",
    "\n",
    "        # Gravnet step\n",
    "        x, edge_index, edge_weight = self.conv1(x)\n",
    "        x = self.act_f(x)                 # act by nonlinearity\n",
    "\n",
    "        # DNN to predict PID\n",
    "        pred_ids = self.nn2(x)\n",
    "\n",
    "        # DNN to predict p4\n",
    "        nn3_input = torch.cat([x, pred_ids, x0], axis=-1)\n",
    "        pred_p4 = self.nn3(nn3_input)\n",
    "\n",
    "        return pred_ids, pred_p4, data.ygen_id, data.ygen, data.ycand_id, data.ycand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelizing the inference..\n",
      "DataParallel(\n",
      "  (module): PFNet7(\n",
      "    (nn1): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=64, out_features=12, bias=True)\n",
      "    )\n",
      "    (conv1): GravNetConv(12, 64, k=16)\n",
      "    (nn2): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "    (nn3): Sequential(\n",
      "      (0): Linear(in_features=82, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Average inference time per event:  0.03437 s\n"
     ]
    }
   ],
   "source": [
    "#----------------RUNNING AFTER OPTIMIZATION ONLY--------------\n",
    "#EXPECTED TIME: 0.03s\n",
    "#USING PF7NET\n",
    "\n",
    "\n",
    "#from torch_geometric.nn import GravNetConv         # if you want to get it from source code (won't be able to retrieve the adjacency matrix)\n",
    "from gravnet import GravNetConv ###OPTIMIZED###\n",
    "use_gpu = torch.cuda.device_count()>0\n",
    "multi_gpu = torch.cuda.device_count()>1\n",
    "\n",
    "try:\n",
    "    if not (\"CUDA_VISIBLE_DEVICES\" in os.environ):\n",
    "        import setGPU\n",
    "        if multi_gpu:\n",
    "            print('Will use multi_gpu..')\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        else:\n",
    "            print('Will use single_gpu..')\n",
    "except Exception as e:\n",
    "    print(\"Could not import setGPU, running CPU-only\")\n",
    "\n",
    "#define the global base device\n",
    "if use_gpu:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "#Model with gravnet clustering\n",
    "class PFNet7(nn.Module):\n",
    "    def __init__(self,\n",
    "        input_dim=12, hidden_dim=256, hidden_dim_nn1=64, input_encoding=12, encoding_dim=64,\n",
    "        output_dim_id=6,\n",
    "        output_dim_p4=6,\n",
    "        space_dim=4, propagate_dimensions=22, nearest=16,\n",
    "        target=\"gen\"):\n",
    "\n",
    "        super(PFNet7, self).__init__()\n",
    "\n",
    "        self.elu = nn.ELU\n",
    "        self.act_f = torch.nn.functional.leaky_relu\n",
    "\n",
    "        # (1) DNN: encoding/decoding of all tracks and clusters\n",
    "        self.nn1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim_nn1),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim_nn1, hidden_dim_nn1),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim_nn1, input_encoding),\n",
    "        )\n",
    "\n",
    "        # (2) CNN: Gravnet layer\n",
    "        self.conv1 = GravNetConv(input_encoding, encoding_dim, space_dim, propagate_dimensions, nearest)\n",
    "\n",
    "        # (3) DNN layer: classifying PID\n",
    "        self.nn2 = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, output_dim_id),\n",
    "        )\n",
    "\n",
    "        # (4) DNN layer: regressing p4\n",
    "        self.nn3 = nn.Sequential(\n",
    "            nn.Linear(encoding_dim + output_dim_id + input_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.elu(),\n",
    "            nn.Linear(hidden_dim, output_dim_p4),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x0 = data.x\n",
    "\n",
    "        # Encoder/Decoder step\n",
    "        x = self.nn1(x0)\n",
    "\n",
    "        # Gravnet step\n",
    "        x, edge_index, edge_weight = self.conv1(x)\n",
    "        x = self.act_f(x)                 # act by nonlinearity\n",
    "\n",
    "        # DNN to predict PID\n",
    "        pred_ids = self.nn2(x)\n",
    "\n",
    "        # DNN to predict p4\n",
    "        nn3_input = torch.cat([x, pred_ids, x0], axis=-1)\n",
    "        pred_p4 = self.nn3(nn3_input)\n",
    "\n",
    "        return pred_ids, pred_p4, data.ygen_id, data.ygen, data.ycand_id, data.ycand\n",
    "\n",
    "# # -------------------------------------------------------------------------------------\n",
    "# testing inference of a forward pass\n",
    "from graph_data_delphes import PFGraphDataset\n",
    "from data_preprocessing import data_to_loader_ttbar, data_to_loader_qcd\n",
    "\n",
    "# get the dataset\n",
    "full_dataset_ttbar = PFGraphDataset('../../../test_tmp_delphes/data/pythia8_ttbar')\n",
    "full_dataset_qcd = PFGraphDataset('../../../test_tmp_delphes/data/pythia8_qcd')\n",
    "\n",
    "# make data loaders\n",
    "train_loader, valid_loader = data_to_loader_ttbar(full_dataset_ttbar, n_train=1, n_valid=1, batch_size=2)\n",
    "test_loader = data_to_loader_qcd(full_dataset_qcd, n_test=1, batch_size=2)\n",
    "\n",
    "# instantiate a model\n",
    "model = PFNet7()\n",
    "if multi_gpu:\n",
    "    print(\"Parallelizing the inference..\")\n",
    "    model = torch_geometric.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "T=[]\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if multi_gpu:\n",
    "        X = batch\n",
    "    else:\n",
    "        X = batch.to(device)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred_ids_one_hot, pred_p4, gen_ids_one_hot, gen_p4, cand_ids_one_hot, cand_p4 = model(X)\n",
    "    t1 = time.time()\n",
    "    T.append(round((t1-t0),5))\n",
    "\n",
    "    if i==10:\n",
    "        break\n",
    "\n",
    "print('Average inference time per event: ', round(sum(T)/len(T),5), 's')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelizing the inference..\n",
      "DataParallel(\n",
      "  (module): PFNet7(\n",
      "    (nn1): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=64, out_features=12, bias=True)\n",
      "    )\n",
      "    (conv1): GravNetConv(12, 64, k=16)\n",
      "    (nn2): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "    (nn3): Sequential(\n",
      "      (0): Linear(in_features=82, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Parallelizing the inference..\n",
      "DataParallel(\n",
      "  (module): PFNet8(\n",
      "    (nn1): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=64, out_features=12, bias=True)\n",
      "    )\n",
      "    (conv1): GravNetConv(12, 64, k=16)\n",
      "    (nn2): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "    (nn3): Sequential(\n",
      "      (0): Linear(in_features=82, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Average inference time per event(Before Optimization):  0.18969 s\n",
      "Average inference time per event(After  Optimization):  0.01166 s\n"
     ]
    }
   ],
   "source": [
    "#----------------RUNNING BEFORE AND AFTER OPTIMIZATION--------------\n",
    "#EXPECTED TIME: After should be faster\n",
    "#USING PF7NET and PF8NET\n",
    "\n",
    "#from torch_geometric.nn import GravNetConv         # if you want to get it from source code (won't be able to retrieve the adjacency matrix)\n",
    "# from gravnet2 import GravNetConv\n",
    "use_gpu = torch.cuda.device_count()>0\n",
    "multi_gpu = torch.cuda.device_count()>1\n",
    "\n",
    "try:\n",
    "    if not (\"CUDA_VISIBLE_DEVICES\" in os.environ):\n",
    "        import setGPU\n",
    "        if multi_gpu:\n",
    "            print('Will use multi_gpu..')\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        else:\n",
    "            print('Will use single_gpu..')\n",
    "except Exception as e:\n",
    "    print(\"Could not import setGPU, running CPU-only\")\n",
    "\n",
    "#define the global base device\n",
    "if use_gpu:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# # -------------------------------------------------------------------------------------\n",
    "# testing inference of a forward pass\n",
    "from graph_data_delphes import PFGraphDataset\n",
    "from data_preprocessing import data_to_loader_ttbar, data_to_loader_qcd\n",
    "\n",
    "# get the dataset\n",
    "full_dataset_ttbar = PFGraphDataset('../../../test_tmp_delphes/data/pythia8_ttbar')\n",
    "full_dataset_qcd = PFGraphDataset('../../../test_tmp_delphes/data/pythia8_qcd')\n",
    "\n",
    "# make data loaders\n",
    "train_loader, valid_loader = data_to_loader_ttbar(full_dataset_ttbar, n_train=1, n_valid=1, batch_size=2)\n",
    "test_loader = data_to_loader_qcd(full_dataset_qcd, n_test=1, batch_size=2)\n",
    "\n",
    "# instantiate a model\n",
    "model = PFNet7() #after\n",
    "model2 = PFNet8()#before\n",
    "\n",
    "#after\n",
    "if multi_gpu:\n",
    "    print(\"Parallelizing the inference..\")\n",
    "    model = torch_geometric.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "#before\n",
    "if multi_gpu:\n",
    "    print(\"Parallelizing the inference..\")\n",
    "    model2 = torch_geometric.nn.DataParallel(model2)\n",
    "model2.to(device)\n",
    "print(model2)\n",
    "\n",
    "\n",
    "T1 = []#after\n",
    "T2 = []#beofre\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if multi_gpu:\n",
    "        X = batch\n",
    "    else:\n",
    "        X = batch.to(device)\n",
    "    #after\n",
    "    t0 = time.time()\n",
    "    pred_ids_one_hot, pred_p4, gen_ids_one_hot, gen_p4, cand_ids_one_hot, cand_p4 = model(X) \n",
    "    t1 = time.time()\n",
    "    T1.append(round((t1-t0),5))\n",
    "    \n",
    "    #before\n",
    "    t0 = time.time()\n",
    "    pred_ids_one_hot, pred_p4, gen_ids_one_hot, gen_p4, cand_ids_one_hot, cand_p4 = model2(X)\n",
    "    t1 = time.time()\n",
    "    T2.append(round((t1-t0),5))\n",
    "\n",
    "\n",
    "    if i==10:\n",
    "        break\n",
    "        \n",
    "print('Average inference time per event(Before Optimization): ', round(sum(T2)/len(T2),5), 's')\n",
    "print('Average inference time per event(After  Optimization): ', round(sum(T1)/len(T1),5), 's')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
